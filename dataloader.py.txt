# dataloader.py â€” Create PyTorch Dataloaders for GolfDB keypoint detection
import os
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import numpy as np

class GolfDBDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.samples = sorted(os.listdir(root_dir))  # assumes each sample is a subfolder or video clip

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        sample_path = os.path.join(self.root_dir, self.samples[idx])
        frames = []
        for i in range(16):  # assuming 16-frame clip
            frame_path = os.path.join(sample_path, f"{i:02d}.jpg")
            image = Image.open(frame_path).convert("RGB")
            if self.transform:
                image = self.transform(image)
            frames.append(image)
        video_tensor = torch.stack(frames)  # Shape: [T, C, H, W]
        video_tensor = video_tensor.permute(1, 0, 2, 3)  # to [C, T, H, W]

        # Dummy ground truth placeholder (to be replaced with actual labels)
        keypoints = torch.rand(13, 2)  # 13 keypoints with (x, y)

        return video_tensor, keypoints

def get_train_loader(batch_size=16):
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor()
    ])
    train_dataset = GolfDBDataset("data/golfdb_dataset/train", transform=transform)
    return DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)

def get_validation_loader(batch_size=16):
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor()
    ])
    val_dataset = GolfDBDataset("data/golfdb_dataset/val", transform=transform)
    return DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)
